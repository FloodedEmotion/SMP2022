{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1108691-5b90-442e-b91b-fca4ab08467c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-06-03 10:38:35.362086: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-03 10:38:37.071243: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-03 10:38:37.071438: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-03 10:38:37.071454: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n",
    "from transformers import AutoConfig\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2e7e854-b22d-4645-a3b8-22f3d54fd727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "NUM_FOLDS = 5\n",
    "NUM_EPOCHS = 2\n",
    "BATCH_SIZE = 64\n",
    "MAX_LEN = 248\n",
    "EVAL_SCHEDULE = [(0.50, 32), (0.49, 16), (0.48, 8), (0.47, 4), (-1., 1)]\n",
    "ROBERTA_PATH = \"./output/\"\n",
    "TOKENIZER_PATH = \"'roberta-base'\"\n",
    "DEVICE = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7d5934-2792-42ba-b0a1-9daf591473d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_random_seed(random_seed):\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(random_seed)\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "357a14fc-5b14-4e38-b0ff-ac16ff850139",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rock punk transgender tranny electronicmusic e...</td>\n",
       "      <td>11.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brazil rio brasil riodejaneiro by maria fifa m...</td>\n",
       "      <td>15.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>old cinema beauty marilyn photoshop movie joke...</td>\n",
       "      <td>10.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pictures old family scans brothers sister 1958...</td>\n",
       "      <td>8.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hot sahara animal animals desert bottles drink...</td>\n",
       "      <td>11.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486189</th>\n",
       "      <td>natur nature frog sea lake fish outdoor macro ...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486190</th>\n",
       "      <td>11 arisk okruh veternov 2016 10 jn preov veter...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486191</th>\n",
       "      <td>holland netherlands amsterdam cat nl ramses gu...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486192</th>\n",
       "      <td>street people bw white black netherlands monoc...</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486193</th>\n",
       "      <td>flower nature fleur extrieure</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>486194 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  excerpt  target\n",
       "0       rock punk transgender tranny electronicmusic e...   11.18\n",
       "1       brazil rio brasil riodejaneiro by maria fifa m...   15.15\n",
       "2       old cinema beauty marilyn photoshop movie joke...   10.99\n",
       "3       pictures old family scans brothers sister 1958...    8.63\n",
       "4       hot sahara animal animals desert bottles drink...   11.16\n",
       "...                                                   ...     ...\n",
       "486189  natur nature frog sea lake fish outdoor macro ...    0.00\n",
       "486190  11 arisk okruh veternov 2016 10 jn preov veter...    0.00\n",
       "486191  holland netherlands amsterdam cat nl ramses gu...    0.00\n",
       "486192  street people bw white black netherlands monoc...    0.00\n",
       "486193                      flower nature fleur extrieure    0.00\n",
       "\n",
       "[486194 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.read_csv('../data/forauto.csv')\n",
    "alltags = all_data[['Alltags','label']]\n",
    "alltags.columns = ['excerpt', 'target']\n",
    "train = alltags[:-180581]\n",
    "test = alltags[-180581:]\n",
    "test = test.reset_index(drop=True)\n",
    "alltags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3896e7a2-b7e6-45a8-8bf4-f8ec3050ade7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vintage toys cool nikon peace lego free retro ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sky people musician paris tower john poetry ki...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paris seine river skeleton fossil rivedroite d...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reading book community library libraries maine...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reading book community library libraries maine...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180576</th>\n",
       "      <td>natur nature frog sea lake fish outdoor macro ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180577</th>\n",
       "      <td>11 arisk okruh veternov 2016 10 jn preov veter...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180578</th>\n",
       "      <td>holland netherlands amsterdam cat nl ramses gu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180579</th>\n",
       "      <td>street people bw white black netherlands monoc...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180580</th>\n",
       "      <td>flower nature fleur extrieure</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180581 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  excerpt  target\n",
       "0       vintage toys cool nikon peace lego free retro ...     0.0\n",
       "1       sky people musician paris tower john poetry ki...     0.0\n",
       "2       paris seine river skeleton fossil rivedroite d...     0.0\n",
       "3       reading book community library libraries maine...     0.0\n",
       "4       reading book community library libraries maine...     0.0\n",
       "...                                                   ...     ...\n",
       "180576  natur nature frog sea lake fish outdoor macro ...     0.0\n",
       "180577  11 arisk okruh veternov 2016 10 jn preov veter...     0.0\n",
       "180578  holland netherlands amsterdam cat nl ramses gu...     0.0\n",
       "180579  street people bw white black netherlands monoc...     0.0\n",
       "180580                      flower nature fleur extrieure     0.0\n",
       "\n",
       "[180581 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c05c9afc-9ff7-4447-8816-ec8f00b3b89f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = train\n",
    "test_df = test\n",
    "del train\n",
    "del test\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "179bb72c-5d3a-44f8-9bd9-58f9da8f3559",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitDataset(Dataset):\n",
    "    def __init__(self, df, inference_only=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.df = df        \n",
    "        self.inference_only = inference_only\n",
    "        self.text = df.excerpt.tolist()\n",
    "        #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n",
    "        \n",
    "        if not self.inference_only:\n",
    "            self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n",
    "    \n",
    "        self.encoded = tokenizer.batch_encode_plus(\n",
    "            self.text,\n",
    "            padding = 'max_length',            \n",
    "            max_length = MAX_LEN,\n",
    "            truncation = True,\n",
    "            return_attention_mask=True\n",
    "        )        \n",
    " \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        input_ids = torch.tensor(self.encoded['input_ids'][index])\n",
    "        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n",
    "        \n",
    "        if self.inference_only:\n",
    "            return (input_ids, attention_mask)            \n",
    "        else:\n",
    "            target = self.target[index]\n",
    "            return (input_ids, attention_mask, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ce4cde1-c398-4d61-ba82-269f93b40f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        config = AutoConfig.from_pretrained(ROBERTA_PATH)\n",
    "        config.update({\"output_hidden_states\":True, \n",
    "                       \"hidden_dropout_prob\": 0.0,\n",
    "                       \"layer_norm_eps\": 1e-7})                       \n",
    "        \n",
    "        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n",
    "            \n",
    "        self.attention = nn.Sequential(            \n",
    "            nn.Linear(768, 512),            \n",
    "            nn.Tanh(),                       \n",
    "            nn.Linear(512, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )        \n",
    "\n",
    "        self.regressor = nn.Sequential(                        \n",
    "            nn.Linear(768, 1)                        \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        roberta_output = self.roberta(input_ids=input_ids,\n",
    "                                      attention_mask=attention_mask)        \n",
    "\n",
    "        # There are a total of 13 layers of hidden states.\n",
    "        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n",
    "        # We take the hidden states from the last Roberta layer.\n",
    "        last_layer_hidden_states = roberta_output.hidden_states[-1]\n",
    "\n",
    "        # The number of cells is MAX_LEN.\n",
    "        # The size of the hidden state of each cell is 768 (for roberta-base).\n",
    "        # In order to condense hidden states of all cells to a context vector,\n",
    "        # we compute a weighted average of the hidden states of all cells.\n",
    "        # We compute the weight of each cell, using the attention neural network.\n",
    "        weights = self.attention(last_layer_hidden_states)\n",
    "                \n",
    "        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n",
    "        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n",
    "        # Now we compute context_vector as the weighted average.\n",
    "        # context_vector.shape is BATCH_SIZE x 768\n",
    "        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n",
    "        \n",
    "        # Now we reduce the context vector to the prediction score.\n",
    "        return self.regressor(context_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94451c42-ec18-45dc-91f0-c683cf4aa207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_mse(model, data_loader):\n",
    "    \"\"\"Evaluates the mean squared error of the |model| on |data_loader|\"\"\"\n",
    "    model.eval()            \n",
    "    mse_sum = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask, target) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)                        \n",
    "            target = target.to(DEVICE)           \n",
    "            \n",
    "            pred = model(input_ids, attention_mask)                       \n",
    "\n",
    "            mse_sum += nn.MSELoss(reduction=\"sum\")(pred.flatten(), target).item()\n",
    "                \n",
    "\n",
    "    return mse_sum / len(data_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c68bdbf8-30ad-4575-b29b-610a23932b89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    result = np.zeros(len(data_loader.dataset))    \n",
    "    index = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)\n",
    "                        \n",
    "            pred = model(input_ids, attention_mask)                        \n",
    "\n",
    "            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n",
    "            index += pred.shape[0]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3389b508-9f36-4ac4-bb91-0f83b94b94b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, model_path, train_loader, val_loader,\n",
    "          optimizer, scheduler=None, num_epochs=NUM_EPOCHS):    \n",
    "    best_val_rmse = None\n",
    "    best_epoch = 0\n",
    "    step = 0\n",
    "    last_eval_step = 0\n",
    "    eval_period = EVAL_SCHEDULE[0][1]    \n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):                           \n",
    "        val_rmse = None         \n",
    "\n",
    "        for batch_num, (input_ids, attention_mask, target) in enumerate(train_loader):\n",
    "            input_ids = input_ids.to(DEVICE)\n",
    "            attention_mask = attention_mask.to(DEVICE)            \n",
    "            target = target.to(DEVICE)                        \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "            pred = model(input_ids, attention_mask)\n",
    "                                                        \n",
    "            mse = nn.MSELoss(reduction=\"mean\")(pred.flatten(), target)\n",
    "                        \n",
    "            mse.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "            \n",
    "            if step >= last_eval_step + eval_period:\n",
    "                # Evaluate the model on val_loader.\n",
    "                elapsed_seconds = time.time() - start\n",
    "                num_steps = step - last_eval_step\n",
    "                print(f\"\\n{num_steps} steps took {elapsed_seconds:0.3} seconds\")\n",
    "                last_eval_step = step\n",
    "                \n",
    "                val_rmse = math.sqrt(eval_mse(model, val_loader))                            \n",
    "\n",
    "                print(f\"Epoch: {epoch} batch_num: {batch_num}\", \n",
    "                      f\"val_rmse: {val_rmse:0.4}\")\n",
    "\n",
    "                for rmse, period in EVAL_SCHEDULE:\n",
    "                    if val_rmse >= rmse:\n",
    "                        eval_period = period\n",
    "                        break                               \n",
    "                \n",
    "                if not best_val_rmse or val_rmse < best_val_rmse:                    \n",
    "                    best_val_rmse = val_rmse\n",
    "                    best_epoch = epoch\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "                    print(f\"New best_val_rmse: {best_val_rmse:0.4}\")\n",
    "                else:       \n",
    "                    print(f\"Still best_val_rmse: {best_val_rmse:0.4}\",\n",
    "                          f\"(from epoch {best_epoch})\")                                    \n",
    "                    \n",
    "                start = time.time()\n",
    "                                            \n",
    "            step += 1\n",
    "                        \n",
    "    \n",
    "    return best_val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49a01c14-a641-4071-ac89-83338059901b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_optimizer(model):\n",
    "    named_parameters = list(model.named_parameters())    \n",
    "    \n",
    "    roberta_parameters = named_parameters[:197]    \n",
    "    attention_parameters = named_parameters[199:203]\n",
    "    regressor_parameters = named_parameters[203:]\n",
    "        \n",
    "    attention_group = [params for (name, params) in attention_parameters]\n",
    "    regressor_group = [params for (name, params) in regressor_parameters]\n",
    "\n",
    "    parameters = []\n",
    "    parameters.append({\"params\": attention_group})\n",
    "    parameters.append({\"params\": regressor_group})\n",
    "\n",
    "    for layer_num, (name, params) in enumerate(roberta_parameters):\n",
    "        weight_decay = 0.0 if \"bias\" in name else 0.01\n",
    "\n",
    "        lr = 2e-5\n",
    "\n",
    "        if layer_num >= 69:        \n",
    "            lr = 5e-5\n",
    "\n",
    "        if layer_num >= 133:\n",
    "            lr = 1e-4\n",
    "\n",
    "        parameters.append({\"params\": params,\n",
    "                           \"weight_decay\": weight_decay,\n",
    "                           \"lr\": lr})\n",
    "\n",
    "    return AdamW(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5665990a-0d0e-4ccb-ade0-dd93a9b03578",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./output/ were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at ./output/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "32 steps took 20.2 seconds\n",
      "Epoch: 0 batch_num: 32 val_rmse: 2.247\n",
      "New best_val_rmse: 2.247\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 64 val_rmse: 2.088\n",
      "New best_val_rmse: 2.088\n",
      "\n",
      "32 steps took 18.6 seconds\n",
      "Epoch: 0 batch_num: 96 val_rmse: 2.025\n",
      "New best_val_rmse: 2.025\n",
      "\n",
      "32 steps took 18.6 seconds\n",
      "Epoch: 0 batch_num: 128 val_rmse: 2.099\n",
      "Still best_val_rmse: 2.025 (from epoch 0)\n",
      "\n",
      "32 steps took 18.7 seconds\n",
      "Epoch: 0 batch_num: 160 val_rmse: 1.9\n",
      "New best_val_rmse: 1.9\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 192 val_rmse: 1.893\n",
      "New best_val_rmse: 1.893\n",
      "\n",
      "32 steps took 18.7 seconds\n",
      "Epoch: 0 batch_num: 224 val_rmse: 1.765\n",
      "New best_val_rmse: 1.765\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 256 val_rmse: 1.732\n",
      "New best_val_rmse: 1.732\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 288 val_rmse: 1.734\n",
      "Still best_val_rmse: 1.732 (from epoch 0)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 0 batch_num: 320 val_rmse: 1.814\n",
      "Still best_val_rmse: 1.732 (from epoch 0)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 0 batch_num: 352 val_rmse: 1.67\n",
      "New best_val_rmse: 1.67\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 0 batch_num: 384 val_rmse: 1.649\n",
      "New best_val_rmse: 1.649\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 416 val_rmse: 1.597\n",
      "New best_val_rmse: 1.597\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 448 val_rmse: 1.576\n",
      "New best_val_rmse: 1.576\n",
      "\n",
      "32 steps took 18.5 seconds\n",
      "Epoch: 0 batch_num: 480 val_rmse: 1.568\n",
      "New best_val_rmse: 1.568\n",
      "\n",
      "32 steps took 18.7 seconds\n",
      "Epoch: 0 batch_num: 512 val_rmse: 1.585\n",
      "Still best_val_rmse: 1.568 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 544 val_rmse: 1.549\n",
      "New best_val_rmse: 1.549\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 576 val_rmse: 1.571\n",
      "Still best_val_rmse: 1.549 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 608 val_rmse: 1.556\n",
      "Still best_val_rmse: 1.549 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 640 val_rmse: 1.51\n",
      "New best_val_rmse: 1.51\n",
      "\n",
      "32 steps took 18.7 seconds\n",
      "Epoch: 0 batch_num: 672 val_rmse: 1.519\n",
      "Still best_val_rmse: 1.51 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 704 val_rmse: 1.577\n",
      "Still best_val_rmse: 1.51 (from epoch 0)\n",
      "\n",
      "32 steps took 18.7 seconds\n",
      "Epoch: 0 batch_num: 736 val_rmse: 1.512\n",
      "Still best_val_rmse: 1.51 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 768 val_rmse: 1.52\n",
      "Still best_val_rmse: 1.51 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 800 val_rmse: 1.483\n",
      "New best_val_rmse: 1.483\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 832 val_rmse: 1.526\n",
      "Still best_val_rmse: 1.483 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 864 val_rmse: 1.468\n",
      "New best_val_rmse: 1.468\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 896 val_rmse: 1.52\n",
      "Still best_val_rmse: 1.468 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 928 val_rmse: 1.462\n",
      "New best_val_rmse: 1.462\n",
      "\n",
      "32 steps took 18.7 seconds\n",
      "Epoch: 0 batch_num: 960 val_rmse: 1.458\n",
      "New best_val_rmse: 1.458\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 992 val_rmse: 1.483\n",
      "Still best_val_rmse: 1.458 (from epoch 0)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 1024 val_rmse: 1.441\n",
      "New best_val_rmse: 1.441\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1056 val_rmse: 1.417\n",
      "New best_val_rmse: 1.417\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1088 val_rmse: 1.423\n",
      "Still best_val_rmse: 1.417 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1120 val_rmse: 1.42\n",
      "Still best_val_rmse: 1.417 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1152 val_rmse: 1.421\n",
      "Still best_val_rmse: 1.417 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1184 val_rmse: 1.412\n",
      "New best_val_rmse: 1.412\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1216 val_rmse: 1.398\n",
      "New best_val_rmse: 1.398\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1248 val_rmse: 1.405\n",
      "Still best_val_rmse: 1.398 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1280 val_rmse: 1.397\n",
      "New best_val_rmse: 1.397\n",
      "\n",
      "32 steps took 18.6 seconds\n",
      "Epoch: 0 batch_num: 1312 val_rmse: 1.392\n",
      "New best_val_rmse: 1.392\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1344 val_rmse: 1.424\n",
      "Still best_val_rmse: 1.392 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1376 val_rmse: 1.376\n",
      "New best_val_rmse: 1.376\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1408 val_rmse: 1.43\n",
      "Still best_val_rmse: 1.376 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1440 val_rmse: 1.386\n",
      "Still best_val_rmse: 1.376 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1472 val_rmse: 1.421\n",
      "Still best_val_rmse: 1.376 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1504 val_rmse: 1.378\n",
      "Still best_val_rmse: 1.376 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1536 val_rmse: 1.373\n",
      "New best_val_rmse: 1.373\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1568 val_rmse: 1.382\n",
      "Still best_val_rmse: 1.373 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1600 val_rmse: 1.362\n",
      "New best_val_rmse: 1.362\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1632 val_rmse: 1.385\n",
      "Still best_val_rmse: 1.362 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1664 val_rmse: 1.374\n",
      "Still best_val_rmse: 1.362 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1696 val_rmse: 1.371\n",
      "Still best_val_rmse: 1.362 (from epoch 0)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 0 batch_num: 1728 val_rmse: 1.359\n",
      "New best_val_rmse: 1.359\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1760 val_rmse: 1.351\n",
      "New best_val_rmse: 1.351\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 0 batch_num: 1792 val_rmse: 1.372\n",
      "Still best_val_rmse: 1.351 (from epoch 0)\n",
      "\n",
      "32 steps took 18.7 seconds\n",
      "Epoch: 0 batch_num: 1824 val_rmse: 1.325\n",
      "New best_val_rmse: 1.325\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1856 val_rmse: 1.347\n",
      "Still best_val_rmse: 1.325 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1888 val_rmse: 1.328\n",
      "Still best_val_rmse: 1.325 (from epoch 0)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 1920 val_rmse: 1.352\n",
      "Still best_val_rmse: 1.325 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1952 val_rmse: 1.364\n",
      "Still best_val_rmse: 1.325 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 1984 val_rmse: 1.312\n",
      "New best_val_rmse: 1.312\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 2016 val_rmse: 1.338\n",
      "Still best_val_rmse: 1.312 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 2048 val_rmse: 1.35\n",
      "Still best_val_rmse: 1.312 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 2080 val_rmse: 1.419\n",
      "Still best_val_rmse: 1.312 (from epoch 0)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 2112 val_rmse: 1.347\n",
      "Still best_val_rmse: 1.312 (from epoch 0)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 2144 val_rmse: 1.307\n",
      "New best_val_rmse: 1.307\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 2176 val_rmse: 1.296\n",
      "New best_val_rmse: 1.296\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 2208 val_rmse: 1.35\n",
      "Still best_val_rmse: 1.296 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 2240 val_rmse: 1.396\n",
      "Still best_val_rmse: 1.296 (from epoch 0)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 2272 val_rmse: 1.309\n",
      "Still best_val_rmse: 1.296 (from epoch 0)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 2304 val_rmse: 1.31\n",
      "Still best_val_rmse: 1.296 (from epoch 0)\n",
      "\n",
      "32 steps took 19.1 seconds\n",
      "Epoch: 0 batch_num: 2336 val_rmse: 1.301\n",
      "Still best_val_rmse: 1.296 (from epoch 0)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 0 batch_num: 2368 val_rmse: 1.308\n",
      "Still best_val_rmse: 1.296 (from epoch 0)\n",
      "\n",
      "32 steps took 19.1 seconds\n",
      "Epoch: 0 batch_num: 2400 val_rmse: 1.298\n",
      "Still best_val_rmse: 1.296 (from epoch 0)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 0 batch_num: 2432 val_rmse: 1.272\n",
      "New best_val_rmse: 1.272\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 2464 val_rmse: 1.308\n",
      "Still best_val_rmse: 1.272 (from epoch 0)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 2496 val_rmse: 1.312\n",
      "Still best_val_rmse: 1.272 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 2528 val_rmse: 1.315\n",
      "Still best_val_rmse: 1.272 (from epoch 0)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 0 batch_num: 2560 val_rmse: 1.291\n",
      "Still best_val_rmse: 1.272 (from epoch 0)\n",
      "\n",
      "32 steps took 19.1 seconds\n",
      "Epoch: 0 batch_num: 2592 val_rmse: 1.292\n",
      "Still best_val_rmse: 1.272 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 2624 val_rmse: 1.311\n",
      "Still best_val_rmse: 1.272 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 2656 val_rmse: 1.348\n",
      "Still best_val_rmse: 1.272 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 2688 val_rmse: 1.332\n",
      "Still best_val_rmse: 1.272 (from epoch 0)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 2720 val_rmse: 1.268\n",
      "New best_val_rmse: 1.268\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 2752 val_rmse: 1.265\n",
      "New best_val_rmse: 1.265\n",
      "\n",
      "32 steps took 19.1 seconds\n",
      "Epoch: 0 batch_num: 2784 val_rmse: 1.276\n",
      "Still best_val_rmse: 1.265 (from epoch 0)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 2816 val_rmse: 1.27\n",
      "Still best_val_rmse: 1.265 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 2848 val_rmse: 1.288\n",
      "Still best_val_rmse: 1.265 (from epoch 0)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 2880 val_rmse: 1.264\n",
      "New best_val_rmse: 1.264\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 2912 val_rmse: 1.243\n",
      "New best_val_rmse: 1.243\n",
      "\n",
      "32 steps took 19.2 seconds\n",
      "Epoch: 0 batch_num: 2944 val_rmse: 1.248\n",
      "Still best_val_rmse: 1.243 (from epoch 0)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 0 batch_num: 2976 val_rmse: 1.244\n",
      "Still best_val_rmse: 1.243 (from epoch 0)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 3008 val_rmse: 1.25\n",
      "Still best_val_rmse: 1.243 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3040 val_rmse: 1.249\n",
      "Still best_val_rmse: 1.243 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3072 val_rmse: 1.263\n",
      "Still best_val_rmse: 1.243 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3104 val_rmse: 1.239\n",
      "New best_val_rmse: 1.239\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3136 val_rmse: 1.237\n",
      "New best_val_rmse: 1.237\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3168 val_rmse: 1.238\n",
      "Still best_val_rmse: 1.237 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3200 val_rmse: 1.236\n",
      "New best_val_rmse: 1.236\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3232 val_rmse: 1.241\n",
      "Still best_val_rmse: 1.236 (from epoch 0)\n",
      "\n",
      "32 steps took 18.7 seconds\n",
      "Epoch: 0 batch_num: 3264 val_rmse: 1.261\n",
      "Still best_val_rmse: 1.236 (from epoch 0)\n",
      "\n",
      "32 steps took 18.7 seconds\n",
      "Epoch: 0 batch_num: 3296 val_rmse: 1.228\n",
      "New best_val_rmse: 1.228\n",
      "\n",
      "32 steps took 18.7 seconds\n",
      "Epoch: 0 batch_num: 3328 val_rmse: 1.258\n",
      "Still best_val_rmse: 1.228 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3360 val_rmse: 1.266\n",
      "Still best_val_rmse: 1.228 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3392 val_rmse: 1.236\n",
      "Still best_val_rmse: 1.228 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3424 val_rmse: 1.23\n",
      "Still best_val_rmse: 1.228 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3456 val_rmse: 1.281\n",
      "Still best_val_rmse: 1.228 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3488 val_rmse: 1.218\n",
      "New best_val_rmse: 1.218\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3520 val_rmse: 1.217\n",
      "New best_val_rmse: 1.217\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3552 val_rmse: 1.21\n",
      "New best_val_rmse: 1.21\n",
      "\n",
      "32 steps took 18.7 seconds\n",
      "Epoch: 0 batch_num: 3584 val_rmse: 1.245\n",
      "Still best_val_rmse: 1.21 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3616 val_rmse: 1.222\n",
      "Still best_val_rmse: 1.21 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3648 val_rmse: 1.213\n",
      "Still best_val_rmse: 1.21 (from epoch 0)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 3680 val_rmse: 1.208\n",
      "New best_val_rmse: 1.208\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 0 batch_num: 3712 val_rmse: 1.202\n",
      "New best_val_rmse: 1.202\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 0 batch_num: 3744 val_rmse: 1.22\n",
      "Still best_val_rmse: 1.202 (from epoch 0)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 0 batch_num: 3776 val_rmse: 1.199\n",
      "New best_val_rmse: 1.199\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 0 batch_num: 3808 val_rmse: 1.208\n",
      "Still best_val_rmse: 1.199 (from epoch 0)\n",
      "\n",
      "32 steps took 20.4 seconds\n",
      "Epoch: 1 batch_num: 20 val_rmse: 1.201\n",
      "Still best_val_rmse: 1.199 (from epoch 0)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 1 batch_num: 52 val_rmse: 1.232\n",
      "Still best_val_rmse: 1.199 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 1 batch_num: 84 val_rmse: 1.222\n",
      "Still best_val_rmse: 1.199 (from epoch 0)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 116 val_rmse: 1.202\n",
      "Still best_val_rmse: 1.199 (from epoch 0)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 148 val_rmse: 1.207\n",
      "Still best_val_rmse: 1.199 (from epoch 0)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 180 val_rmse: 1.202\n",
      "Still best_val_rmse: 1.199 (from epoch 0)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 1 batch_num: 212 val_rmse: 1.185\n",
      "New best_val_rmse: 1.185\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 1 batch_num: 244 val_rmse: 1.203\n",
      "Still best_val_rmse: 1.185 (from epoch 1)\n",
      "\n",
      "32 steps took 19.1 seconds\n",
      "Epoch: 1 batch_num: 276 val_rmse: 1.201\n",
      "Still best_val_rmse: 1.185 (from epoch 1)\n",
      "\n",
      "32 steps took 19.2 seconds\n",
      "Epoch: 1 batch_num: 308 val_rmse: 1.208\n",
      "Still best_val_rmse: 1.185 (from epoch 1)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 1 batch_num: 340 val_rmse: 1.182\n",
      "New best_val_rmse: 1.182\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 372 val_rmse: 1.2\n",
      "Still best_val_rmse: 1.182 (from epoch 1)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 1 batch_num: 404 val_rmse: 1.193\n",
      "Still best_val_rmse: 1.182 (from epoch 1)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 1 batch_num: 436 val_rmse: 1.177\n",
      "New best_val_rmse: 1.177\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 468 val_rmse: 1.181\n",
      "Still best_val_rmse: 1.177 (from epoch 1)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 500 val_rmse: 1.203\n",
      "Still best_val_rmse: 1.177 (from epoch 1)\n",
      "\n",
      "32 steps took 19.1 seconds\n",
      "Epoch: 1 batch_num: 532 val_rmse: 1.189\n",
      "Still best_val_rmse: 1.177 (from epoch 1)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 1 batch_num: 564 val_rmse: 1.188\n",
      "Still best_val_rmse: 1.177 (from epoch 1)\n",
      "\n",
      "32 steps took 19.1 seconds\n",
      "Epoch: 1 batch_num: 596 val_rmse: 1.186\n",
      "Still best_val_rmse: 1.177 (from epoch 1)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 628 val_rmse: 1.202\n",
      "Still best_val_rmse: 1.177 (from epoch 1)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 1 batch_num: 660 val_rmse: 1.183\n",
      "Still best_val_rmse: 1.177 (from epoch 1)\n",
      "\n",
      "32 steps took 18.7 seconds\n",
      "Epoch: 1 batch_num: 692 val_rmse: 1.195\n",
      "Still best_val_rmse: 1.177 (from epoch 1)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 1 batch_num: 724 val_rmse: 1.18\n",
      "Still best_val_rmse: 1.177 (from epoch 1)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 756 val_rmse: 1.2\n",
      "Still best_val_rmse: 1.177 (from epoch 1)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 1 batch_num: 788 val_rmse: 1.185\n",
      "Still best_val_rmse: 1.177 (from epoch 1)\n",
      "\n",
      "32 steps took 19.2 seconds\n",
      "Epoch: 1 batch_num: 820 val_rmse: 1.191\n",
      "Still best_val_rmse: 1.177 (from epoch 1)\n",
      "\n",
      "32 steps took 19.2 seconds\n",
      "Epoch: 1 batch_num: 852 val_rmse: 1.183\n",
      "Still best_val_rmse: 1.177 (from epoch 1)\n",
      "\n",
      "32 steps took 19.1 seconds\n",
      "Epoch: 1 batch_num: 884 val_rmse: 1.165\n",
      "New best_val_rmse: 1.165\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 1 batch_num: 916 val_rmse: 1.195\n",
      "Still best_val_rmse: 1.165 (from epoch 1)\n",
      "\n",
      "32 steps took 18.7 seconds\n",
      "Epoch: 1 batch_num: 948 val_rmse: 1.175\n",
      "Still best_val_rmse: 1.165 (from epoch 1)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 1 batch_num: 980 val_rmse: 1.165\n",
      "New best_val_rmse: 1.165\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 1012 val_rmse: 1.162\n",
      "New best_val_rmse: 1.162\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 1 batch_num: 1044 val_rmse: 1.163\n",
      "Still best_val_rmse: 1.162 (from epoch 1)\n",
      "\n",
      "32 steps took 19.1 seconds\n",
      "Epoch: 1 batch_num: 1076 val_rmse: 1.163\n",
      "Still best_val_rmse: 1.162 (from epoch 1)\n",
      "\n",
      "32 steps took 19.1 seconds\n",
      "Epoch: 1 batch_num: 1108 val_rmse: 1.169\n",
      "Still best_val_rmse: 1.162 (from epoch 1)\n",
      "\n",
      "32 steps took 19.1 seconds\n",
      "Epoch: 1 batch_num: 1140 val_rmse: 1.163\n",
      "Still best_val_rmse: 1.162 (from epoch 1)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 1 batch_num: 1172 val_rmse: 1.156\n",
      "New best_val_rmse: 1.156\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 1204 val_rmse: 1.158\n",
      "Still best_val_rmse: 1.156 (from epoch 1)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 1 batch_num: 1236 val_rmse: 1.165\n",
      "Still best_val_rmse: 1.156 (from epoch 1)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 1 batch_num: 1268 val_rmse: 1.163\n",
      "Still best_val_rmse: 1.156 (from epoch 1)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 1300 val_rmse: 1.16\n",
      "Still best_val_rmse: 1.156 (from epoch 1)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 1332 val_rmse: 1.158\n",
      "Still best_val_rmse: 1.156 (from epoch 1)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 1364 val_rmse: 1.155\n",
      "New best_val_rmse: 1.155\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 1396 val_rmse: 1.154\n",
      "New best_val_rmse: 1.154\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 1428 val_rmse: 1.153\n",
      "New best_val_rmse: 1.153\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 1 batch_num: 1460 val_rmse: 1.151\n",
      "New best_val_rmse: 1.151\n",
      "\n",
      "32 steps took 18.7 seconds\n",
      "Epoch: 1 batch_num: 1492 val_rmse: 1.171\n",
      "Still best_val_rmse: 1.151 (from epoch 1)\n",
      "\n",
      "32 steps took 18.8 seconds\n",
      "Epoch: 1 batch_num: 1524 val_rmse: 1.164\n",
      "Still best_val_rmse: 1.151 (from epoch 1)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 1556 val_rmse: 1.15\n",
      "New best_val_rmse: 1.15\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 1588 val_rmse: 1.161\n",
      "Still best_val_rmse: 1.15 (from epoch 1)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 1 batch_num: 1620 val_rmse: 1.155\n",
      "Still best_val_rmse: 1.15 (from epoch 1)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 1 batch_num: 1652 val_rmse: 1.146\n",
      "New best_val_rmse: 1.146\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 1684 val_rmse: 1.154\n",
      "Still best_val_rmse: 1.146 (from epoch 1)\n",
      "\n",
      "32 steps took 19.1 seconds\n",
      "Epoch: 1 batch_num: 1716 val_rmse: 1.146\n",
      "Still best_val_rmse: 1.146 (from epoch 1)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 1 batch_num: 1748 val_rmse: 1.139\n",
      "New best_val_rmse: 1.139\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 1 batch_num: 1780 val_rmse: 1.143\n",
      "Still best_val_rmse: 1.139 (from epoch 1)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 1812 val_rmse: 1.146\n",
      "Still best_val_rmse: 1.139 (from epoch 1)\n",
      "\n",
      "32 steps took 19.2 seconds\n",
      "Epoch: 1 batch_num: 1844 val_rmse: 1.146\n",
      "Still best_val_rmse: 1.139 (from epoch 1)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 1876 val_rmse: 1.169\n",
      "Still best_val_rmse: 1.139 (from epoch 1)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 1 batch_num: 1908 val_rmse: 1.141\n",
      "Still best_val_rmse: 1.139 (from epoch 1)\n",
      "\n",
      "32 steps took 19.1 seconds\n",
      "Epoch: 1 batch_num: 1940 val_rmse: 1.148\n",
      "Still best_val_rmse: 1.139 (from epoch 1)\n",
      "\n",
      "32 steps took 19.1 seconds\n",
      "Epoch: 1 batch_num: 1972 val_rmse: 1.147\n",
      "Still best_val_rmse: 1.139 (from epoch 1)\n",
      "\n",
      "32 steps took 19.3 seconds\n",
      "Epoch: 1 batch_num: 2004 val_rmse: 1.15\n",
      "Still best_val_rmse: 1.139 (from epoch 1)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 2036 val_rmse: 1.141\n",
      "Still best_val_rmse: 1.139 (from epoch 1)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 2068 val_rmse: 1.142\n",
      "Still best_val_rmse: 1.139 (from epoch 1)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 2100 val_rmse: 1.141\n",
      "Still best_val_rmse: 1.139 (from epoch 1)\n",
      "\n",
      "32 steps took 18.9 seconds\n",
      "Epoch: 1 batch_num: 2132 val_rmse: 1.14\n",
      "Still best_val_rmse: 1.139 (from epoch 1)\n",
      "\n",
      "32 steps took 19.0 seconds\n",
      "Epoch: 1 batch_num: 2164 val_rmse: 1.138\n",
      "New best_val_rmse: 1.138\n",
      "\n",
      "32 steps took 19.0 seconds\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "\n",
    "SEED = 1000\n",
    "list_val_rmse = []\n",
    "\n",
    "kfold = KFold(n_splits=NUM_FOLDS, random_state=SEED, shuffle=True)\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kfold.split(train_df)):    \n",
    "    print(f\"\\nFold {fold + 1}/{NUM_FOLDS}\")\n",
    "    model_path = f\"model_{fold + 1}.pth\"\n",
    "        \n",
    "    set_random_seed(SEED + fold)\n",
    "    \n",
    "    train_dataset = LitDataset(train_df.loc[train_indices])    \n",
    "    val_dataset = LitDataset(train_df.loc[val_indices])    \n",
    "        \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,\n",
    "                              drop_last=True, shuffle=True, num_workers=2)    \n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE,\n",
    "                            drop_last=False, shuffle=False, num_workers=2)    \n",
    "        \n",
    "    set_random_seed(SEED + fold)    \n",
    "    \n",
    "    model = LitModel().to(DEVICE)\n",
    "    \n",
    "    optimizer = create_optimizer(model)                        \n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_training_steps=NUM_EPOCHS * len(train_loader),\n",
    "        num_warmup_steps=50)    \n",
    "    \n",
    "    list_val_rmse.append(train(model, model_path, train_loader,\n",
    "                               val_loader, optimizer, scheduler=scheduler))\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"\\nPerformance estimates:\")\n",
    "    print(list_val_rmse)\n",
    "    print(\"Mean:\", np.array(list_val_rmse).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be659a4-6a9e-4a3b-81ec-8575c966ab73",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = LitDataset(test_df, inference_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a37dff-e0ac-4b96-b147-463f4650f71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = np.zeros((len(list_val_rmse), len(test_df)))\n",
    "\n",
    "test_dataset = LitDataset(test_df, inference_only=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
    "                         drop_last=False, shuffle=False, num_workers=2)\n",
    "\n",
    "for index in range(len(list_val_rmse)):            \n",
    "    model_path = f\"model_{index + 1}.pth\"\n",
    "    print(f\"\\nUsing {model_path}\")\n",
    "                        \n",
    "    model = LitModel()\n",
    "    model.load_state_dict(torch.load(model_path))    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    all_predictions[index] = predict(model, test_loader)\n",
    "    \n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442108be-9f38-427b-a0b1-5f90abf26220",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = all_predictions.mean(axis=0)\n",
    "submission_df.target = predictions\n",
    "print(submission_df)\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2010d481-f10b-4643-ab35-564c49cfd690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
