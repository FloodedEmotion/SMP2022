{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e5d20f1-8f10-400b-bb1c-05d5cd9da31a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import plotly.express as px\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy.matlib\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from joblib import Parallel, delayed\n",
    "import shutil\n",
    "import glob\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "from pytorch_tabnet.metrics import Metric\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.random.seed(0)\n",
    "import os\n",
    "import torch\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingWarmRestarts\n",
    "from scipy.stats import norm, skew\n",
    "# train\n",
    "\n",
    "all_data = pd.read_csv('../data/feature_data_530.csv')\n",
    "# glove\n",
    "glove_tags = pd.read_csv('../data/alltags_feature.csv')\n",
    "glove_title = pd.read_csv('../data/title_feature.csv')\n",
    "# glove_title = pd.read_csv('../data/title_feature.csv')\n",
    "all_data = pd.concat([all_data, glove_tags, glove_title], axis=1)\n",
    "columns = ['Title_len', 'Title_number', 'Alltags_len', 'Alltags_number', 'photo_count', 'totalTags', 'totalGeotagged', 'totalFaves',\n",
    "          'totalInGroup','photoCount','meanView', 'meanTags', 'meanFaves', 'followerCount','followingCount']\n",
    "skew_features = all_data[columns].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "high_skew = skew_features[abs(skew_features) > 0.75]\n",
    "skew_index = high_skew.index\n",
    "for i in skew_index:\n",
    "    all_data[i] = np.log1p(all_data[i])\n",
    "    \n",
    "useless_columns = ['Pid','mean_label'] \n",
    "useless_columns += ['user_fe_{}'.format(i) for i in range(399)]\n",
    "useless_columns += ['loc_fe_{}'.format(i) for i in range(400)]\n",
    "all_data = all_data.drop(useless_columns, axis=1)\n",
    "\n",
    "\n",
    "train_all_data = all_data[all_data['train_type'] != -1]\n",
    "submit_all_data = all_data[all_data['train_type'] == -1]\n",
    "feature_columns = ['train_type','label']\n",
    "all_data = all_data.drop(feature_columns, axis=1)\n",
    "\n",
    "train_all_data = train_all_data.reset_index(drop=True)\n",
    "submit_all_data = submit_all_data.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb61aeb-c07c-42b5-ab72-29b4e97fa12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extracr BLIP  scores of the text_image pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892fee36-ff3b-4747-b253-6ba201ff9623",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305613 180581 682\n",
      "305613 180581 682\n"
     ]
    }
   ],
   "source": [
    "train_label_df = train_all_data[['label']]\n",
    "train_feature_df = train_all_data.drop(feature_columns, axis=1)\n",
    "\n",
    "submit_label_df = submit_all_data[['label']]\n",
    "submit_feature_df = submit_all_data.drop(feature_columns, axis=1)\n",
    "\n",
    "print(len(train_feature_df), len(submit_feature_df), len(train_feature_df.columns))\n",
    "print(len(train_label_df), len(submit_label_df), len(train_feature_df.columns))\n",
    "cate_cols = ['Uid', 'Category', 'Subcategory', 'Concept', 'Mediatype', 'hour', 'day', 'weekday', 'week_hour', 'year_weekday','Geoaccuracy', 'ispro' , 'Ispublic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "523fd021-5043-444e-9db4-2a202aa5eb14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580aba22-5d08-4baa-a2b4-aa501e19cd9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.18.2.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import numpy as np \n",
    "# import pandas as pd\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# from umap import UMAP\n",
    "from sklearn.cluster import KMeans\n",
    "from haversine import haversine\n",
    "\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "bold = ['\\033[1m', '\\033[0m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1666caaf-6fd8-4cf6-a50e-268a3068dab7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pip/_internal/commands/install.py:255: UserWarning: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\n",
      "  cmdoptions.check_install_build_global(options)\n",
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.8/dist-packages (3.3.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.8/dist-packages (from lightgbm) (1.2.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from lightgbm) (1.24.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from lightgbm) (1.10.1)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from lightgbm) (0.34.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install lightgbm --install-option=--gpu --install-option=\"--boost-root=C:/local/boost_1_69_0\" --install-option=\"--boost-librarydir=C:/local/boost_1_69_0/lib64-msvc-14.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5f20e59-aafe-48f7-b533-d9165743db02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pip/_internal/commands/install.py:255: UserWarning: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\n",
      "  cmdoptions.check_install_build_global(options)\n",
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.8/dist-packages (3.3.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from lightgbm) (1.24.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from lightgbm) (1.10.1)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from lightgbm) (0.34.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.8/dist-packages (from lightgbm) (1.2.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install lightgbm --install-option=--gpu --install-option=\"--opencl-include-dir=/usr/local/cuda/include/\" --install-option=\"--opencl-library=/usr/local/cuda/lib64/libOpenCL.so\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d519ee70-1de2-408d-8701-34a2e6603e28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  cmake-data libarchive13 libcurl4 libjsoncpp1 librhash0 libuv1\n",
      "Suggested packages:\n",
      "  cmake-doc ninja-build lrzip\n",
      "The following NEW packages will be installed:\n",
      "  cmake cmake-data libarchive13 libcurl4 libjsoncpp1 librhash0 libuv1\n",
      "0 upgraded, 7 newly installed, 0 to remove and 58 not upgraded.\n",
      "Need to get 6113 kB of archives.\n",
      "After this operation, 30.2 MB of additional disk space will be used.\n",
      "Do you want to continue? [Y/n] ^C\n"
     ]
    }
   ],
   "source": [
    "# !apt install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96c2783a-ce71-4d16-af6b-0429052f4fa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: cmake: command not found\n"
     ]
    }
   ],
   "source": [
    "!cmake --DUSE_CUDA=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b2759fb-2cf6-4267-8c07-c12f7c29cf6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n",
    "def f_importance_plot(f_imp):\n",
    "    fig = plt.figure(figsize = (15, 0.35*len(f_imp)))\n",
    "    plt.title('Feature importances', size=25, y=1.05, \n",
    "              fontname='Calibri', fontweight='bold', color='#444444')\n",
    "    a = sns.barplot(data=f_imp, x='avg_imp', y='feature', \n",
    "                    palette='Blues_d', linestyle=\"-\", \n",
    "                    linewidth=1, edgecolor=\"black\")\n",
    "    plt.xlabel('')\n",
    "    plt.xticks([])\n",
    "    plt.ylabel('')\n",
    "    plt.yticks(size=11, color='#444444')\n",
    "    \n",
    "    for j in ['right', 'top', 'bottom']:\n",
    "        a.spines[j].set_visible(False)\n",
    "    for j in ['left']:\n",
    "        a.spines[j].set_linewidth(0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d874c8d-87b8-47fd-a0cb-ce95623c31f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCMake Warning:\n",
      "  No source or binary directory provided.  Both will be assumed to be the\n",
      "  same as the current working directory, but note that this warning will\n",
      "  become a fatal error in future CMake releases.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mCMake Error at CMakeLists.txt:101 (include):\n",
      "  include could not find requested file:\n",
      "\n",
      "    CompileFlags.cmake\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[0mCMake Error: File /MMChallenge/SMP/HyFea-main/Utilities/std/cmSTL.hxx.in does not exist.\u001b[0m\n",
      "\u001b[31mCMake Error at CMakeLists.txt:112 (configure_file):\n",
      "  configure_file Problem configuring file\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[0mCMake Error: File /MMChallenge/SMP/HyFea-main/.clang-tidy does not exist.\u001b[0m\n",
      "\u001b[31mCMake Error at CMakeLists.txt:307 (configure_file):\n",
      "  configure_file Problem configuring file\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mCMake Error at CMakeLists.txt:739 (include):\n",
      "  include could not find requested file:\n",
      "\n",
      "    /MMChallenge/SMP/HyFea-main/Tests/CMakeInstall.cmake\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mCMake Error at CMakeLists.txt:346 (include):\n",
      "  include could not find requested file:\n",
      "\n",
      "    Utilities/cmThirdPartyChecks.cmake\n",
      "Call Stack (most recent call first):\n",
      "  CMakeLists.txt:777 (CMAKE_BUILD_UTILITIES)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[0mCMake Error: File /MMChallenge/SMP/HyFea-main/cmake_uninstall.cmake.in does not exist.\u001b[0m\n",
      "\u001b[31mCMake Error at CMakeLists.txt:802 (configure_file):\n",
      "  configure_file Problem configuring file\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mCMake Error at CMakeLists.txt:809 (include):\n",
      "  include could not find requested file:\n",
      "\n",
      "    CMakeCPack.cmake\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[0mCMake Error: File /MMChallenge/SMP/HyFea-main/Templates/CTestScript.cmake.in does not exist.\u001b[0m\n",
      "\u001b[31mCMake Error at CMakeLists.txt:260 (configure_file):\n",
      "  configure_file Problem configuring file\n",
      "Call Stack (most recent call first):\n",
      "  CMakeLists.txt:814 (CMAKE_SETUP_TESTING)\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mCMake Error at CMakeLists.txt:843 (add_subdirectory):\n",
      "  add_subdirectory given source \"Utilities\" which is not an existing\n",
      "  directory.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mCMake Error at CMakeLists.txt:846 (add_subdirectory):\n",
      "  add_subdirectory given source \"Tests\" which is not an existing directory.\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mCMake Error at CMakeLists.txt:888 (add_subdirectory):\n",
      "  add_subdirectory given source \"Auxiliary\" which is not an existing\n",
      "  directory.\n",
      "\n",
      "\u001b[0m\n",
      "-- Configuring incomplete, errors occurred!\n",
      "See also \"/MMChallenge/SMP/HyFea-main/CMakeFiles/CMakeOutput.log\".\n",
      "See also \"/MMChallenge/SMP/HyFea-main/CMakeFiles/CMakeError.log\".\n"
     ]
    }
   ],
   "source": [
    "!cmake -DUSE_GPU=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67b8a73a-6078-454b-9722-84a9cbcb2ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FOLD 1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 40\u001b[0m\n\u001b[1;32m     32\u001b[0m lgb_train \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(data\u001b[38;5;241m=\u001b[39mtrain_feature_df\u001b[38;5;241m.\u001b[39miloc[train_idx], \n\u001b[1;32m     33\u001b[0m                         label\u001b[38;5;241m=\u001b[39mtrain_label_df\u001b[38;5;241m.\u001b[39miloc[train_idx],\n\u001b[1;32m     34\u001b[0m                         categorical_feature\u001b[38;5;241m=\u001b[39mcate_cols)\n\u001b[1;32m     35\u001b[0m lgb_valid \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(data\u001b[38;5;241m=\u001b[39mtrain_feature_df\u001b[38;5;241m.\u001b[39miloc[val_idx], \n\u001b[1;32m     36\u001b[0m                         label\u001b[38;5;241m=\u001b[39mtrain_label_df\u001b[38;5;241m.\u001b[39miloc[val_idx],\n\u001b[1;32m     37\u001b[0m                         categorical_feature\u001b[38;5;241m=\u001b[39mcate_cols,\n\u001b[1;32m     38\u001b[0m                         reference\u001b[38;5;241m=\u001b[39mlgb_train)\n\u001b[0;32m---> 40\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlgb_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlgb_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlgb_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlgb_valid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m f_imp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(fold\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfeature_importance()\n\u001b[1;32m     50\u001b[0m b_itr \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/lightgbm/engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    273\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/lightgbm/basic.py:2610\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2608\u001b[0m params_str \u001b[38;5;241m=\u001b[39m param_dict_to_str(params)\n\u001b[1;32m   2609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_void_p()\n\u001b[0;32m-> 2610\u001b[0m \u001b[43m_safe_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterCreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2613\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2614\u001b[0m \u001b[38;5;66;03m# save reference to data\u001b[39;00m\n\u001b[1;32m   2615\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_set \u001b[38;5;241m=\u001b[39m train_set\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/lightgbm/basic.py:125\u001b[0m, in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m    The return value from C API calls.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB\u001b[38;5;241m.\u001b[39mLGBM_GetLastError()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mLightGBMError\u001b[0m: GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from scipy import stats\n",
    "from sklearn.metrics import f1_score, mean_absolute_error, mean_squared_error\n",
    "lgb_params = {\n",
    "    'max_depth': 9,\n",
    "    'learning_rate': 0.01,\n",
    "    # 'min_data_in_leaf': 36, \n",
    "    # 'num_leaves': 100, \n",
    "    # 'feature_fraction': 0.8, \n",
    "    # 'bagging_fraction': 0.89, \n",
    "    # 'bagging_freq': 5, \n",
    "    # 'lambda_l2': 28,\n",
    "    # 'seed': seed,\n",
    "    'objective': 'regression',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'device': 'gpu', \n",
    "    # 'gpu_platform_id': 0,\n",
    "    'gpu_device_id': 0,\n",
    "    'n_jobs': -1,\n",
    "    'metric': 'rmse',\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "f_imp = pd.DataFrame({'feature': train_feature_df.columns})\n",
    "predictions, scores = np.zeros(len(submit_feature_df)), []\n",
    "\n",
    "k = KFold(n_splits=5, random_state=2020, shuffle=True)\n",
    "for fold, (train_idx, val_idx) in enumerate(k.split(train_feature_df, train_label_df)):\n",
    "    print(f'\\n--- FOLD {fold+1} ---')\n",
    "        \n",
    "    lgb_train = lgb.Dataset(data=train_feature_df.iloc[train_idx], \n",
    "                            label=train_label_df.iloc[train_idx],\n",
    "                            categorical_feature=cate_cols)\n",
    "    lgb_valid = lgb.Dataset(data=train_feature_df.iloc[val_idx], \n",
    "                            label=train_label_df.iloc[val_idx],\n",
    "                            categorical_feature=cate_cols,\n",
    "                            reference=lgb_train)\n",
    "\n",
    "    model = lgb.train(params=lgb_params, \n",
    "                      train_set=lgb_train, \n",
    "                      num_boost_round=50000,\n",
    "                      valid_sets=[lgb_train, lgb_valid], \n",
    "                      valid_names=['train', 'val'],\n",
    "                      verbose_eval=False,\n",
    "                      callbacks=[lgb.log_evaluation(1000),\n",
    "                                 lgb.early_stopping(1000, verbose=False)])\n",
    "    \n",
    "    f_imp['fold_'+str(fold+1)] = model.feature_importance()\n",
    "    b_itr = model.best_iteration\n",
    "    \n",
    "    val_preds = model.predict(train_feature_df.iloc[val_idx], num_iteration=b_itr)\n",
    "    val_score = rmse(train_label_df['label'].iloc[val_idx], val_preds)\n",
    "    val_mae = mean_squared_error(train_label_df['label'].iloc[val_idx], val_preds)\n",
    "    val_src = stats.spearmanr(train_label_df['label'].iloc[val_idx], val_preds)[0]\n",
    "    scores.append(val_score)\n",
    "    print(\"valid: MSE: %.4f, MAE: %.4f, SRC: %.4f\"%(val_score, val_mae,val_src))\n",
    "    predictions += model.predict(submit_feature_df, num_iteration=b_itr) / 5\n",
    "    print(f'--- RMSE: {bold[0]}{round(val_score, 6)}{bold[1]} | best iteration: {bold[0]}{b_itr}{bold[1]} ---')\n",
    "    \n",
    "    del lgb_train, lgb_valid, val_preds, val_score, model\n",
    "    gc.collect()\n",
    "\n",
    "print('*'*45)\n",
    "print(f'Mean RMSE: {bold[0]}{round(np.mean(scores), 6)}{bold[1]}')\n",
    "\n",
    "f_imp['avg_imp'] = f_imp[f_imp.columns[1:]].mean(axis=1)\n",
    "f_imp.sort_values('avg_imp', ascending=False, inplace=True)\n",
    "f_importance_plot(f_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817e992-9adf-40e2-95a0-e1efc6bc4135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgbm_preds = predictions.copy()\n",
    "ss['LGBM_pred'] = predictions\n",
    "ss.to_csv('lgbm_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5951bd19-b2a5-45bb-86b3-6ff3e9cfd44f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in cate_cols:\n",
    "    train_feature_df[i] = train_feature_df[i].astype(\"category\")\n",
    "    submit_feature_df[i] = submit_feature_df[i].astype(\"category\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7919a88f-d4da-4726-bc0c-bfabb35b5b3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## use xgboost for regression\n",
    "\n",
    "xgb_params = {\n",
    "    'max_depth': 9,\n",
    "    # 'max_cat_to_onehot':6,\n",
    "    'eta': 0.01,\n",
    "    # 'colsample_bytree': 0.66,\n",
    "    # 'subsample': 0.76,\n",
    "    # 'min_child_weight': 22,\n",
    "    'lambda': 16, \n",
    "    'gamma': 1,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'booster': 'gbtree',\n",
    "    'predictor':'gpu_predictor',\n",
    "    'seed': seed,\n",
    "    'gpu_id':0,\n",
    "    'enable_categorical':True,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "f_imp = pd.DataFrame({'feature': train_feature_df.columns})\n",
    "predictions, scores = np.zeros(len(submit_feature_df)), []\n",
    "\n",
    "k = KFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "for fold, (train_idx, val_idx) in enumerate(k.split(train_feature_df, train_label_df)):\n",
    "    print(f'\\n--- FOLD {fold+1} ---')\n",
    "    \n",
    "    dtrain = xgb.DMatrix(train_feature_df.iloc[train_idx], label=train_label_df.iloc[train_idx])\n",
    "    dvalid = xgb.DMatrix(train_feature_df.iloc[val_idx], label=train_label_df.iloc[val_idx])\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "\n",
    "    model = xgb.train(params=xgb_params, \n",
    "                      dtrain=dtrain, \n",
    "                      num_boost_round=50000,\n",
    "                      evals=watchlist, \n",
    "                      verbose_eval=5000,\n",
    "                      callbacks=[xgb.callback.EarlyStopping(rounds=1000,\n",
    "                                                            data_name='eval',\n",
    "                                                            maximize=False,\n",
    "                                                            save_best=True)])\n",
    "    \n",
    "    fi = model.get_score(importance_type='weight')\n",
    "    fi = pd.DataFrame({'feature':fi.keys(),f'importance_{fold}':fi.values()})\n",
    "    f_imp = f_imp.merge(fi, on='feature', how='left').fillna(0)\n",
    "    b_itr = model.best_ntree_limit\n",
    "    \n",
    "    val_preds = model.predict(dvalid)\n",
    "    val_score = rmse(train_label_df['label'].iloc[val_idx], val_preds)\n",
    "    val_mae = mean_squared_error(train_label_df['label'].iloc[val_idx], val_preds)\n",
    "    val_src = stats.spearmanr(train_label_df['label'].iloc[val_idx], val_preds)[0]\n",
    "    scores.append(val_score)\n",
    "    print(\"valid: MSE: %.4f, MAE: %.4f, SRC: %.4f\"%(val_score, val_mae,val_src))\n",
    "    \n",
    "    predictions += model.predict(xgb.DMatrix(submit_feature_df)) / 5\n",
    "    print(f'--- RMSE: {bold[0]}{round(val_score, 6)}{bold[1]} | best iteration: {bold[0]}{b_itr}{bold[1]} ---')\n",
    "    \n",
    "    del dtrain, dvalid, watchlist, val_preds, val_score, model\n",
    "    gc.collect()\n",
    "\n",
    "print('*'*45)\n",
    "print(f'Mean RMSE: {bold[0]}{round(np.mean(scores), 6)}{bold[1]}')\n",
    "\n",
    "f_imp['avg_imp'] = f_imp[f_imp.columns[1:]].mean(axis=1)\n",
    "f_imp.sort_values('avg_imp', ascending=False, inplace=True)\n",
    "f_importance_plot(f_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1432c8e-3df0-4fef-adf3-99008e853276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb_preds = predictions.copy()\n",
    "ss['xgb_pre'] = predictions\n",
    "ss.to_csv('xgb_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea73a34-bee2-4b63-987b-a957eb71c59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d577cb41-d084-4b6c-9e15-b031cac74b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
