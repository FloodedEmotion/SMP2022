{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b826ace6-c8fc-4d12-b06e-2fd4ed3d65ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 21:26:09.064568: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-02 21:26:10.661680: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-02 21:26:10.661774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-06-02 21:26:10.661786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "import os \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4,5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f968188-b578-4a0e-859d-e01219e56ec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305613 180581 682\n",
      "305613 180581 682\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(666)\n",
    "all_data = pd.read_csv('../data/feature_data_530.csv')\n",
    "# glove\n",
    "glove_tags = pd.read_csv('../data/alltags_feature.csv')\n",
    "glove_title = pd.read_csv('../data/title_feature.csv')\n",
    "all_data = pd.concat([all_data, glove_tags, glove_title],axis=1)\n",
    "train_all_data = all_data[all_data['train_type'] != -1]\n",
    "submit_all_data = all_data[all_data['train_type'] == -1]\n",
    "train_all_data = train_all_data.reset_index(drop=True)\n",
    "submit_all_data = submit_all_data.reset_index(drop=True)\n",
    "\n",
    "feature_columns = ['Pid', 'train_type', 'label', 'mean_label'] \n",
    "feature_columns += ['user_fe_{}'.format(i) for i in range(399)]\n",
    "feature_columns += ['loc_fe_{}'.format(i) for i in range(400)]\n",
    "\n",
    "train_label_df = train_all_data[['label']]\n",
    "train_feature_df = train_all_data.drop(feature_columns, axis=1)\n",
    "\n",
    "submit_label_df = submit_all_data[['label']]\n",
    "submit_feature_df = submit_all_data.drop(feature_columns, axis=1)\n",
    "print(len(train_feature_df), len(submit_feature_df), len(train_feature_df.columns))\n",
    "print(len(train_label_df), len(submit_label_df), len(train_feature_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c44ba188-5d96-443e-8e84-c1723766f5dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_autoencoder():\n",
    "    input_vector = Input(shape=(682,))\n",
    "    encoded = Dense(2000, activation='elu')(input_vector)\n",
    "    encoded = Dense(1000, activation='elu')(encoded)\n",
    "    decoded = Dense(2000, activation='elu')(encoded)\n",
    "    decoded = Dense(682, activation='elu')(decoded)\n",
    "    \n",
    "    autoencoder = tf.keras.Model(\n",
    "        input_vector, \n",
    "        decoded\n",
    "    )\n",
    "    \n",
    "    autoencoder.compile(\n",
    "        optimizer='adadelta', \n",
    "        loss='mse'\n",
    "    )\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522a2d75-aa71-4666-ad44-1ef9fbdfda48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder = create_autoencoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485d9294-dd5d-4457-ad0e-cc63adaefd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d82f428-54bb-4a31-a954-d9b9efbe99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 0, 0.05\n",
    "\n",
    "noise = np.random.normal(\n",
    "    mu, \n",
    "    sigma, \n",
    "    [305613, 682]\n",
    ") \n",
    "noised_train = train + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08d6c15-f59f-43c9-a6b2-0912fb66a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(\n",
    "    noised_train, \n",
    "    train, \n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caadf0d1-9587-4181-b030-b49e51d7c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.Model(\n",
    "    autoencoder.input, \n",
    "    autoencoder.layers[2].output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa37835-78a1-40dd-a5a7-60610eb12a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.DataFrame(encoder.predict(train))\n",
    "test_features = pd.DataFrame(encoder.predict(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e66721d-9855-4163-bc10-0c1bc0806f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(1000),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "        tfa.layers.WeightNormalization(tf.keras.layers.Dense(500)),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tfa.layers.WeightNormalization(tf.keras.layers.Dense(500)),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tfa.layers.WeightNormalization(tf.keras.layers.Dense(350)),\n",
    "        tf.keras.layers.LeakyReLU(),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        \n",
    "        tfa.layers.WeightNormalization(\n",
    "            tf.keras.layers.Dense(\n",
    "                206, \n",
    "                activation=\"sigmoid\"\n",
    "            )\n",
    "        )\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tfa.optimizers.AdamW(\n",
    "            lr=1e-3, \n",
    "            weight_decay=1e-5, \n",
    "            # clipvalue=700\n",
    "        ), \n",
    "        loss='binary_crossentropy'\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b5b167-873e-44b8-9c56-a38cb2be79c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.loc[:, train_targets.columns] = 0\n",
    "res = train_targets.copy()\n",
    "for n, (tr, te) in enumerate(KFold(n_splits=7, random_state=666, shuffle=True).split(train_targets)):\n",
    "    print(f'Fold {n}')\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    model.fit(\n",
    "        train_features.values[tr],\n",
    "        train_targets.values[tr],\n",
    "        epochs=50, \n",
    "        batch_size=128\n",
    "    )\n",
    "    \n",
    "    submission.loc[:, train_targets.columns] += model.predict(test_features)\n",
    "    res.loc[te, train_targets.columns] = model.predict(train_features.values[te])\n",
    "    \n",
    "submission.loc[:, train_targets.columns] /= (n+1)\n",
    "\n",
    "metrics = []\n",
    "for _target in train_targets.columns:\n",
    "    metrics.append(log_loss(train_targets.loc[:, _target], res.loc[:, _target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8724ee32-184a-48e6-be0c-84ef6f8d179f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'OOF Metric: {np.mean(metrics)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9e148-d7a6-45da-b222-a0c0f71d1606",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['cp_type'] = test_cp_type\n",
    "for col in submission.columns:\n",
    "    if col in ['sig_id', 'cp_type', 'cp_dose', 'cp_time']:\n",
    "        continue\n",
    "    submission.loc[submission['cp_type'] == 'ctl_vehicle', col] = 0\n",
    "\n",
    "submission = submission.drop(['cp_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ebfea5-bb8d-4569-a59c-18beee7f4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
